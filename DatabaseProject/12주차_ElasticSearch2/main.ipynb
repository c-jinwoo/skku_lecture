{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \\[40pts\\] Implement the various functions for common Elasticsearch operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (6.0.1)\n",
      "Requirement already satisfied: elasticsearch in /opt/conda/lib/python3.11/site-packages (8.11.0)\n",
      "Requirement already satisfied: elasticsearch_dsl in /opt/conda/lib/python3.11/site-packages (8.11.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /opt/conda/lib/python3.11/site-packages (from elasticsearch) (8.10.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from elasticsearch_dsl) (2.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/conda/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil->elasticsearch_dsl) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml elasticsearch elasticsearch_dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "from src.elasticsearch_client import ElasticsearchClient\n",
    "from data.index_mapping import mapping\n",
    "import json\n",
    "\n",
    "INDEX_NAME = \"movie_reviews_homework8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'es01', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'wHtB8J4jTvyxGs6FJBICDQ', 'version': {'number': '8.10.4', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'b4a62ac808e886ff032700c391f45f1408b2538c', 'build_date': '2023-10-11T22:04:35.506990650Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "es_client = ElasticsearchClient()\n",
    "print(es_client.client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete index if exists before creating a new one\n",
    "try:\n",
    "    ###### EDIT HERE ######\n",
    "    es_client.delete_index(index_name=INDEX_NAME)\n",
    "    ###### EDIT HERE ######\n",
    "except Exception as e:\n",
    "    print(f\"Error {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index based on mapping\n",
    "###### EDIT HERE ######\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"movieId\": {\n",
    "                \"type\": \"integer\" # Fill in the blank\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"genres\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"imdbId\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"tmdbId\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"userId\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"rating\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"timestamp\": {\n",
    "                \"type\": \"date\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es_client.create_index(index_name=INDEX_NAME, mapping=mapping)\n",
    "###### EDIT HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"./data/movie_data_big.json\", \"r\") as f:\n",
    "    movie_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert only one document with doc_id == 0\n",
    "doc_id = 0\n",
    "\n",
    "###### EDIT HERE ######\n",
    "for idx, document in enumerate(movie_data):\n",
    "    if idx == doc_id:\n",
    "        es_client.insert_one_document(index_name=INDEX_NAME, body=document, doc_id=doc_id)\n",
    "        break\n",
    "###### EDIT HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete document with doc_id == 0\n",
    "doc_id = 0\n",
    "\n",
    "###### EDIT HERE ######\n",
    "es_client.delete_document(index_name=INDEX_NAME, doc_id=doc_id)\n",
    "###### EDIT HERE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100789\n"
     ]
    }
   ],
   "source": [
    "# insert all documents using bulk indexing\n",
    "actions = []\n",
    "for id_doc, doc in enumerate(movie_data):\n",
    "    \n",
    "###### EDIT HERE ######\n",
    "    action = {\n",
    "        \"_op_type\": \"index\",\n",
    "        \"_index\": INDEX_NAME,\n",
    "        \"_id\": id_doc,\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    actions.append(action)\n",
    "\n",
    "es_client.bulk_request(actions=actions)\n",
    "###### EDIT HERE ######\n",
    "\n",
    "print(len(actions)) # should be 100789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document with id 85453: {'movieId': 54259, 'title': 'Stardust (2007)', 'genres': 'Adventure|Comedy|Fantasy|Romance', 'imdbId': 486655, 'tmdbId': 2270.0, 'userId': 414, 'rating': 3.5, 'timestamp': 1203130241000}\n"
     ]
    }
   ],
   "source": [
    "# get document with doc_id == 85453\n",
    "doc_id = 85453\n",
    "\n",
    "###### EDIT HERE ######\n",
    "try:\n",
    "    doc = es_client.get_document(index_name=INDEX_NAME, doc_id=doc_id)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    \n",
    "###### EDIT HERE ######\n",
    "\n",
    "print(f\"document with id 85453: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100789\n"
     ]
    }
   ],
   "source": [
    "# get count of all documents in the index\n",
    "count = 0\n",
    "\n",
    "###### EDIT HERE ######\n",
    "count = es_client.count(index_name=INDEX_NAME)\n",
    "###### EDIT HERE ######\n",
    "\n",
    "print(count) # should be 100789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 87925, Title: Star Wars: The Clone Wars (2008), userID: 21\n",
      "ID: 87926, Title: Star Wars: The Clone Wars (2008), userID: 220\n",
      "ID: 87927, Title: Star Wars: The Clone Wars (2008), userID: 298\n",
      "ID: 87928, Title: Star Wars: The Clone Wars (2008), userID: 380\n",
      "ID: 87929, Title: Star Wars: The Clone Wars (2008), userID: 414\n",
      "ID: 87930, Title: Star Wars: The Clone Wars (2008), userID: 489\n",
      "ID: 87931, Title: Star Wars: The Clone Wars (2008), userID: 534\n",
      "ID: 98955, Title: The Star Wars Holiday Special (1978), userID: 514\n",
      "ID: 100626, Title: Star Wars: The Last Jedi (2017), userID: 62\n",
      "ID: 100627, Title: Star Wars: The Last Jedi (2017), userID: 98\n"
     ]
    }
   ],
   "source": [
    "# search for documents with title containing \"star wars\"\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_phrase\": {\n",
    "            \"title\": \"star wars\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "results = es_client.search(index_name=INDEX_NAME, query=query)\n",
    "###### EDIT HERE ######\n",
    "for res in results: # should be 10 documents\n",
    "    print(f\"ID: {res['_id']}, Title: {res['_source']['title']}, userID: {res['_source']['userId']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \\[10pts\\] Compare the difference in execution time between basic and helper operations and report the result and your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_and_create_index(es_client, index_name, mapping):\n",
    "    try:\n",
    "        es_client.delete_index(index_name=index_name)\n",
    "        es_client.create_index(index_name=index_name, mapping=mapping)\n",
    "    except Exception as e:\n",
    "        print(f\"Error {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index deleted\n"
     ]
    }
   ],
   "source": [
    "delete_and_create_index(es_client, INDEX_NAME, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100789it [23:38, 71.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting all documents without bulk took 1418.2433474063873 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# insert all documents not using bulk\n",
    "start = time.time()\n",
    "for id_doc, doc in tqdm(enumerate(movie_data)):\n",
    "    es_client.insert_one_document(index_name=INDEX_NAME, body=doc, doc_id=id_doc)\n",
    "end = time.time()\n",
    "print(f\"Inserting all documents without bulk took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index deleted\n",
      "Inserting all documents with bulk took 8.524917602539062 seconds\n"
     ]
    }
   ],
   "source": [
    "# insert all documents using bulk\n",
    "delete_and_create_index(es_client, INDEX_NAME, mapping)\n",
    "\n",
    "start = time.time()\n",
    "actions = []\n",
    "for id_doc, doc in enumerate(movie_data):\n",
    "###### EDIT HERE ######\n",
    "    action = {\n",
    "        \"_op_type\": \"index\",\n",
    "        \"_index\": INDEX_NAME,\n",
    "        \"_id\": id_doc,\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    actions.append(action)\n",
    "\n",
    "es_client.bulk_request(actions=actions)\n",
    "###### EDIT HERE ######\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Inserting all documents with bulk took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "query2 = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"match\": {\"genres\": \"Action\"}},\n",
    "                {\"match\": {\"genres\": \"Crime\"}}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87571\n",
      "Retrieving all documents with 10 took 17.140448570251465 seconds\n",
      "100789\n",
      "Retrieving all documents with 1000 took 0.8979315757751465 seconds\n",
      "6781\n",
      "Retrieving all documents with 10 took 1.2961006164550781 seconds\n",
      "6781\n",
      "Retrieving all documents with 1000 took 0.12001395225524902 seconds\n"
     ]
    }
   ],
   "source": [
    "page_size=[10, 1000]\n",
    "\n",
    "# retrieve all documents with scan\n",
    "for query in [query1, query2]:\n",
    "    for size in page_size:\n",
    "        scroll = es_client.scan_index(query=query, index_name=INDEX_NAME, size=size)\n",
    "\n",
    "        start = time.time()\n",
    "        count = 0\n",
    "        for hit in scroll:\n",
    "            count += 1\n",
    "        print(count)\n",
    "        end = time.time()\n",
    "        print(f\"Retrieving all documents with {size} took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100789\n",
      "Retrieving all documents with search and scroll took 246.6975953578949 seconds\n",
      "6781\n",
      "Retrieving all documents with search and scroll took 16.07894802093506 seconds\n"
     ]
    }
   ],
   "source": [
    "# retrieve all documents with search and scroll\n",
    "\n",
    "for query in [query1, query2]:\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    \n",
    "    response = es_client.client.search(index=INDEX_NAME, body=query)\n",
    "    scroll_response = es_client.client.search(index=INDEX_NAME, body=query, scroll='1m')\n",
    "    \n",
    "    scroll_id = scroll_response['_scroll_id']\n",
    "    for hit in scroll_response['hits']['hits']:\n",
    "        count += 1\n",
    "\n",
    "    while True:\n",
    "        scroll_response = es_client.client.scroll(scroll_id=scroll_id, scroll='1m')\n",
    "        if len(scroll_response['hits']['hits']) == 0:\n",
    "            break\n",
    "        for hit in scroll_response['hits']['hits']:\n",
    "            count += 1\n",
    "    print(count)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Retrieving all documents with search and scroll took {end - start} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
